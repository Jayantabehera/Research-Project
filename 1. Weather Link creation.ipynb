{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install bs4\n",
    "#import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "import time\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from http.client import IncompleteRead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>GlideNumber</th>\n",
       "      <th>Country</th>\n",
       "      <th>OtherCountry</th>\n",
       "      <th>long</th>\n",
       "      <th>lat</th>\n",
       "      <th>Area</th>\n",
       "      <th>Began</th>\n",
       "      <th>Ended</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Dead</th>\n",
       "      <th>Displaced</th>\n",
       "      <th>MainCause</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>0</td>\n",
       "      <td>5.23026</td>\n",
       "      <td>35.81420</td>\n",
       "      <td>92615.67</td>\n",
       "      <td>1985-01-01</td>\n",
       "      <td>1985-01-05</td>\n",
       "      <td>News</td>\n",
       "      <td>26</td>\n",
       "      <td>3000</td>\n",
       "      <td>Heavy rain</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>0</td>\n",
       "      <td>-45.34890</td>\n",
       "      <td>-18.71110</td>\n",
       "      <td>678498.82</td>\n",
       "      <td>1985-01-15</td>\n",
       "      <td>1985-02-02</td>\n",
       "      <td>News</td>\n",
       "      <td>229</td>\n",
       "      <td>80000</td>\n",
       "      <td>Heavy rain</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Phillipines</td>\n",
       "      <td>0</td>\n",
       "      <td>122.97400</td>\n",
       "      <td>10.02070</td>\n",
       "      <td>12846.03</td>\n",
       "      <td>1985-01-20</td>\n",
       "      <td>1985-01-21</td>\n",
       "      <td>News</td>\n",
       "      <td>43</td>\n",
       "      <td>444</td>\n",
       "      <td>Torrential rain</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>0</td>\n",
       "      <td>124.60600</td>\n",
       "      <td>1.01489</td>\n",
       "      <td>16542.12</td>\n",
       "      <td>1985-02-04</td>\n",
       "      <td>1985-02-18</td>\n",
       "      <td>News</td>\n",
       "      <td>21</td>\n",
       "      <td>300</td>\n",
       "      <td>Torrential rain</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Mozambique</td>\n",
       "      <td>0</td>\n",
       "      <td>32.34910</td>\n",
       "      <td>-25.86930</td>\n",
       "      <td>20082.21</td>\n",
       "      <td>1985-02-09</td>\n",
       "      <td>1985-02-11</td>\n",
       "      <td>News</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>Heavy rain</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID GlideNumber      Country OtherCountry       long       lat       Area  \\\n",
       "0   1           0      Algeria            0    5.23026  35.81420   92615.67   \n",
       "1   2           0       Brazil            0  -45.34890 -18.71110  678498.82   \n",
       "2   3           0  Phillipines            0  122.97400  10.02070   12846.03   \n",
       "3   4           0    Indonesia            0  124.60600   1.01489   16542.12   \n",
       "4   5           0   Mozambique            0   32.34910 -25.86930   20082.21   \n",
       "\n",
       "       Began      Ended Validation  Dead  Displaced        MainCause  Severity  \n",
       "0 1985-01-01 1985-01-05       News    26       3000       Heavy rain       1.0  \n",
       "1 1985-01-15 1985-02-02       News   229      80000       Heavy rain       2.0  \n",
       "2 1985-01-20 1985-01-21       News    43        444  Torrential rain       1.0  \n",
       "3 1985-02-04 1985-02-18       News    21        300  Torrential rain       1.0  \n",
       "4 1985-02-09 1985-02-11       News    19          0       Heavy rain       2.0  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"D:\\Research Project\\Datasets\\Flood intensity\\FloodArchive.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to extract weather URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdetails(URL,began_date):\n",
    "    dt_object = began_date.date()\n",
    "    dt_object1 = dt_object-timedelta(days=2) # this is for day-2's values\n",
    "    dt_object = dt_object1\n",
    "    \n",
    "\n",
    "    req = Request(URL, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    webpage = urlopen(req).read()\n",
    "    soup = BeautifulSoup(webpage, 'html.parser')\n",
    "    value1 = str(soup.find_all(\"div\", {\"class\":\"station-name ng-star-inserted\"}))\n",
    "    result_list = re.sub(r\"^.+?(?=history)\", \"\", value1)\n",
    "    \n",
    "    split_string = result_list.split(\"date\", 1)\n",
    "    substring = split_string[0]\n",
    "    \n",
    "    hist_url = 'https://www.wunderground.com/'+substring+'date/'+str(dt_object)+'/'\n",
    "    return hist_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping weather URL based on coordinates and Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200 rows iterated\n",
      "4250 rows iterated\n",
      "4300 rows iterated\n",
      "4350 rows iterated\n",
      "4400 rows iterated\n",
      "4450 rows iterated\n",
      "4500 rows iterated\n",
      "4550 rows iterated\n",
      "4600 rows iterated\n",
      "4650 rows iterated\n",
      "4700 rows iterated\n",
      "4750 rows iterated\n",
      "4800 rows iterated\n",
      "4850 rows iterated\n",
      "4900 rows iterated\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url= \"https://www.wunderground.com/weather/\"\n",
    "for i in range(len(df)):\n",
    "    # adding this line as internet got interrupted inbetween\n",
    "    if i > 4163:\n",
    "        new_url = url + str(df.loc[i, \"lat\"]) + ',' + str(df.loc[i, \"long\"]) +'/'\n",
    "        df.loc[i,\"coordinate url\"]=new_url\n",
    "        try :\n",
    "            val= getdetails(new_url,df.loc[i, \"Began\"])\n",
    "            df.loc[i,\"began date url\"]=val\n",
    "\n",
    "\n",
    "        except IncompleteRead:\n",
    "            # reconnect and keep trucking\n",
    "            continue \n",
    "\n",
    "        if i % 50 ==0:\n",
    "                print(f\"{i} rows iterated\")\n",
    "                # Wait for 5 seconds\n",
    "                #time.sleep(5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Dataframe to extract weather details via UiPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df\n",
    "df.to_csv('D:\\Research Project\\Datasets\\Flood intensity\\data url\\csv files\\date2_url_from_4163.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
